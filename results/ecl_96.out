Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ecl                 Model:              delayformer         

[1mData Loader[0m
  Data:               custom              Root Path:          /home/bingxing2/home/scx8939/wzj/all_datasets/
  Data Path:          electricity/electricity.csvFeatures:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             321                 Dec In:             321                 
  C Out:              7                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               512                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0005              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ecl_delayformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
	iters: 500, epoch: 1 | loss: 0.2333883
	speed: 0.5884s/iter; left time: 6402.4518s
test 5165
	iters: 600, epoch: 1 | loss: 0.2474452
	speed: 0.5882s/iter; left time: 6341.9103s
	iters: 100, epoch: 1 | loss: 0.2774479
	speed: 1.0250s/iter; left time: 5731.0256s
	iters: 700, epoch: 1 | loss: 0.2431343
	speed: 0.5873s/iter; left time: 6272.5428s
slurmstepd: error: *** JOB 190793 ON paraai-n32-h-01-agent-4 CANCELLED AT 2024-04-04T00:57:57 ***
	iters: 200, epoch: 1 | loss: 0.2680132
	speed: 0.9981s/iter; left time: 5480.3920s
	iters: 300, epoch: 1 | loss: 0.2593290
	speed: 0.9989s/iter; left time: 5385.0825s
	iters: 400, epoch: 1 | loss: 0.2694518
	speed: 0.9994s/iter; left time: 5287.6560s
	iters: 500, epoch: 1 | loss: 0.2503662
	speed: 0.9991s/iter; left time: 5186.0960s
Epoch: 1 cost time: 571.8763020038605
Epoch: 1, Steps: 569 | Train Loss: 0.2809348 Vali Loss: 0.1551190 Test Loss: 0.1819305
Validation loss decreased (inf --> 0.155119).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2353159
	speed: 4.9364s/iter; left time: 24790.6825s
	iters: 200, epoch: 2 | loss: 0.2346751
	speed: 0.9957s/iter; left time: 4901.0808s
	iters: 300, epoch: 2 | loss: 0.2242703
	speed: 0.9984s/iter; left time: 4814.2985s
	iters: 400, epoch: 2 | loss: 0.2298078
	speed: 0.9957s/iter; left time: 4701.7997s
	iters: 500, epoch: 2 | loss: 0.2286099
	speed: 0.9943s/iter; left time: 4595.5858s
Epoch: 2 cost time: 567.2807176113129
Epoch: 2, Steps: 569 | Train Loss: 0.2309495 Vali Loss: 0.1423408 Test Loss: 0.1683830
Validation loss decreased (0.155119 --> 0.142341).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2039621
	speed: 4.9323s/iter; left time: 21963.6601s
	iters: 200, epoch: 3 | loss: 0.2082757
	speed: 0.9984s/iter; left time: 4346.1768s
	iters: 300, epoch: 3 | loss: 0.2119124
	speed: 0.9986s/iter; left time: 4247.0432s
	iters: 400, epoch: 3 | loss: 0.2236043
	speed: 0.9990s/iter; left time: 4148.8233s
	iters: 500, epoch: 3 | loss: 0.2212920
	speed: 0.9973s/iter; left time: 4041.8796s
Epoch: 3 cost time: 567.9274563789368
Epoch: 3, Steps: 569 | Train Loss: 0.2176403 Vali Loss: 0.1390222 Test Loss: 0.1655581
Validation loss decreased (0.142341 --> 0.139022).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1927513
	speed: 4.9254s/iter; left time: 19130.1879s
	iters: 200, epoch: 4 | loss: 0.2082148
	speed: 0.9984s/iter; left time: 3777.7757s
	iters: 300, epoch: 4 | loss: 0.1894843
	speed: 0.9940s/iter; left time: 3661.8172s
	iters: 400, epoch: 4 | loss: 0.2146101
	speed: 0.9925s/iter; left time: 3557.2639s
	iters: 500, epoch: 4 | loss: 0.2015944
	speed: 0.9971s/iter; left time: 3474.0633s
Epoch: 4 cost time: 567.1528787612915
Epoch: 4, Steps: 569 | Train Loss: 0.2114988 Vali Loss: 0.1353431 Test Loss: 0.1622871
Validation loss decreased (0.139022 --> 0.135343).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2131897
	speed: 4.9420s/iter; left time: 16382.6261s
	iters: 200, epoch: 5 | loss: 0.2050547
	speed: 0.9975s/iter; left time: 3207.0684s
	iters: 300, epoch: 5 | loss: 0.2101327
	speed: 0.9974s/iter; left time: 3106.9970s
	iters: 400, epoch: 5 | loss: 0.1996218
	speed: 0.9960s/iter; left time: 3002.8584s
	iters: 500, epoch: 5 | loss: 0.1966435
	speed: 0.9956s/iter; left time: 2902.1409s
Epoch: 5 cost time: 567.3812847137451
Epoch: 5, Steps: 569 | Train Loss: 0.2078851 Vali Loss: 0.1363418 Test Loss: 0.1639050
EarlyStopping counter: 1 out of 5
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2030594
	speed: 4.9172s/iter; left time: 13502.6052s
	iters: 200, epoch: 6 | loss: 0.2027017
	speed: 0.9962s/iter; left time: 2635.9726s
	iters: 300, epoch: 6 | loss: 0.2138791
	speed: 0.9977s/iter; left time: 2540.0716s
	iters: 400, epoch: 6 | loss: 0.2024452
	speed: 0.9980s/iter; left time: 2441.1032s
	iters: 500, epoch: 6 | loss: 0.2307151
	speed: 0.9981s/iter; left time: 2341.4954s
Epoch: 6 cost time: 567.3867483139038
Epoch: 6, Steps: 569 | Train Loss: 0.2056494 Vali Loss: 0.1352386 Test Loss: 0.1625868
Validation loss decreased (0.135343 --> 0.135239).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2109280
	speed: 4.9284s/iter; left time: 10729.1455s
	iters: 200, epoch: 7 | loss: 0.2043618
	speed: 0.9952s/iter; left time: 2067.0834s
	iters: 300, epoch: 7 | loss: 0.1976050
	speed: 0.9947s/iter; left time: 1966.5676s
	iters: 400, epoch: 7 | loss: 0.2024568
	speed: 0.9975s/iter; left time: 1872.2754s
	iters: 500, epoch: 7 | loss: 0.2195007
	speed: 0.9972s/iter; left time: 1771.9528s
Epoch: 7 cost time: 566.5784063339233
Epoch: 7, Steps: 569 | Train Loss: 0.2043907 Vali Loss: 0.1349580 Test Loss: 0.1624302
Validation loss decreased (0.135239 --> 0.134958).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2030202
	speed: 4.9355s/iter; left time: 7936.3446s
	iters: 200, epoch: 8 | loss: 0.2284727
	speed: 0.9963s/iter; left time: 1502.4892s
	iters: 300, epoch: 8 | loss: 0.2289262
	speed: 0.9978s/iter; left time: 1404.8620s
	iters: 400, epoch: 8 | loss: 0.2040633
	speed: 0.9967s/iter; left time: 1303.7271s
	iters: 500, epoch: 8 | loss: 0.2026457
	speed: 0.9963s/iter; left time: 1203.5117s
Epoch: 8 cost time: 567.4198291301727
Epoch: 8, Steps: 569 | Train Loss: 0.2036235 Vali Loss: 0.1347653 Test Loss: 0.1622852
Validation loss decreased (0.134958 --> 0.134765).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1917477
	speed: 4.9353s/iter; left time: 5127.7401s
	iters: 200, epoch: 9 | loss: 0.1798077
	speed: 0.9984s/iter; left time: 937.5075s
	iters: 300, epoch: 9 | loss: 0.1897339
	speed: 0.9979s/iter; left time: 837.2177s
	iters: 400, epoch: 9 | loss: 0.2079081
	speed: 0.9976s/iter; left time: 737.1961s
	iters: 500, epoch: 9 | loss: 0.2101511
	speed: 0.9972s/iter; left time: 637.2314s
Epoch: 9 cost time: 567.9107182025909
Epoch: 9, Steps: 569 | Train Loss: 0.2031687 Vali Loss: 0.1342620 Test Loss: 0.1616874
Validation loss decreased (0.134765 --> 0.134262).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2044825
	speed: 4.9254s/iter; left time: 2314.9476s
	iters: 200, epoch: 10 | loss: 0.2195491
	speed: 0.9958s/iter; left time: 368.4298s
	iters: 300, epoch: 10 | loss: 0.2076601
	speed: 0.9953s/iter; left time: 268.7337s
	iters: 400, epoch: 10 | loss: 0.2002111
	speed: 0.9979s/iter; left time: 169.6512s
	iters: 500, epoch: 10 | loss: 0.1964151
	speed: 0.9951s/iter; left time: 69.6574s
Epoch: 10 cost time: 566.8990933895111
Epoch: 10, Steps: 569 | Train Loss: 0.2029985 Vali Loss: 0.1344492 Test Loss: 0.1619378
EarlyStopping counter: 1 out of 5
Updating learning rate to 9.765625e-07
>>>>>>>testing : long_term_forecast_ecl_delayformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.16168685257434845, mae:0.26365146040916443
