Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           weather_336         Model:              delayformer         

[1mData Loader[0m
  Data:               custom              Root Path:          /home/bingxing2/home/scx8939/wzj/all_datasets/
  Data Path:          weather/weather.csv Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           336                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             21                  Dec In:             21                  
  C Out:              7                   d model:            128                 
  n heads:            12                  e layers:           3                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         128                 
  Patience:           3                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_weather_336_delayformer_custom_ftM_sl96_ll48_pl336_dm128_nh12_el3_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36456
val 4935
test 10204
	iters: 100, epoch: 1 | loss: 0.6379345
	speed: 0.2635s/iter; left time: 722.3777s
	iters: 200, epoch: 1 | loss: 0.6532798
	speed: 0.2333s/iter; left time: 616.0549s
Epoch: 1 cost time: 69.42839550971985
Epoch: 1, Steps: 284 | Train Loss: 0.6121839 Vali Loss: 0.5549990 Test Loss: 0.2667665
Validation loss decreased (inf --> 0.554999).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5539871
	speed: 1.4541s/iter; left time: 3572.7872s
	iters: 200, epoch: 2 | loss: 0.6734528
	speed: 0.2328s/iter; left time: 548.7346s
Epoch: 2 cost time: 66.37989640235901
Epoch: 2, Steps: 284 | Train Loss: 0.5819207 Vali Loss: 0.5570157 Test Loss: 0.2686180
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5633767
	speed: 1.4556s/iter; left time: 3162.9356s
	iters: 200, epoch: 3 | loss: 0.4331077
	speed: 0.2328s/iter; left time: 482.6218s
Epoch: 3 cost time: 66.32301878929138
Epoch: 3, Steps: 284 | Train Loss: 0.5708060 Vali Loss: 0.5506867 Test Loss: 0.2655205
Validation loss decreased (0.554999 --> 0.550687).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4785944
	speed: 1.4632s/iter; left time: 2764.0660s
	iters: 200, epoch: 4 | loss: 0.5349458
	speed: 0.2324s/iter; left time: 415.7123s
Epoch: 4 cost time: 66.180180311203
Epoch: 4, Steps: 284 | Train Loss: 0.5661253 Vali Loss: 0.5494691 Test Loss: 0.2658905
Validation loss decreased (0.550687 --> 0.549469).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5804561
	speed: 1.4465s/iter; left time: 2321.7081s
	iters: 200, epoch: 5 | loss: 0.4967616
	speed: 0.2331s/iter; left time: 350.7433s
Epoch: 5 cost time: 66.32832717895508
Epoch: 5, Steps: 284 | Train Loss: 0.5636080 Vali Loss: 0.5475476 Test Loss: 0.2649896
Validation loss decreased (0.549469 --> 0.547548).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4719637
	speed: 1.4655s/iter; left time: 1935.9059s
	iters: 200, epoch: 6 | loss: 0.7042920
	speed: 0.2324s/iter; left time: 283.7659s
Epoch: 6 cost time: 66.1512348651886
Epoch: 6, Steps: 284 | Train Loss: 0.5616225 Vali Loss: 0.5474873 Test Loss: 0.2650254
Validation loss decreased (0.547548 --> 0.547487).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4640441
	speed: 1.4579s/iter; left time: 1511.7936s
	iters: 200, epoch: 7 | loss: 0.5600767
	speed: 0.2330s/iter; left time: 218.3006s
Epoch: 7 cost time: 66.34846806526184
Epoch: 7, Steps: 284 | Train Loss: 0.5605839 Vali Loss: 0.5472002 Test Loss: 0.2651190
Validation loss decreased (0.547487 --> 0.547200).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4760874
	speed: 1.4608s/iter; left time: 1099.9965s
	iters: 200, epoch: 8 | loss: 0.5247275
	speed: 0.2323s/iter; left time: 151.6977s
Epoch: 8 cost time: 66.19587922096252
Epoch: 8, Steps: 284 | Train Loss: 0.5603212 Vali Loss: 0.5460877 Test Loss: 0.2651763
Validation loss decreased (0.547200 --> 0.546088).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5862633
	speed: 1.4504s/iter; left time: 680.2183s
	iters: 200, epoch: 9 | loss: 0.5075368
	speed: 0.2327s/iter; left time: 85.8592s
Epoch: 9 cost time: 66.29149651527405
Epoch: 9, Steps: 284 | Train Loss: 0.5601570 Vali Loss: 0.5458492 Test Loss: 0.2650336
Validation loss decreased (0.546088 --> 0.545849).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.4542120
	speed: 1.4543s/iter; left time: 269.0452s
	iters: 200, epoch: 10 | loss: 0.4936075
	speed: 0.2327s/iter; left time: 19.7753s
Epoch: 10 cost time: 66.32460927963257
Epoch: 10, Steps: 284 | Train Loss: 0.5599409 Vali Loss: 0.5472451 Test Loss: 0.2650536
Validation loss decreased (0.545849 --> 0.547245).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_weather_336_delayformer_custom_ftM_sl96_ll48_pl336_dm128_nh12_el3_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10204
test shape: (10204, 1, 336, 21) (10204, 1, 336, 21)
test shape: (10204, 336, 21) (10204, 336, 21)
mse:0.26505354046821594, mae:0.293051153421402
